# AI와 테스트를 활용한 안정적인 기능 개발 리포트

## 사용하는 도구를 선택한 이유가 있을까요? 각 도구의 특징에 대해 조사해본적이 있나요?
gpt, gemini, claude 세 모델을 다 조금씩은 쓰고 있습니다. codex나 gemini cli도 사용을 고려해보았습니다. 서브 에이전트라는 게 클로드 코드에만 있어서 선택했습니다. 또 커서는 여러 모델을 사용할 수 있다는 게 장점이지만, 기존 대부분의 작업에서 클로드만 쓰고 있습니다. 코딩을 하는 데에는 클로드가 가장 좋은 모델인 것 같습니다. 많은 작문을 챗지피티가 도와줬으며 커서 안의 클로드가 대부분의 작업을 했습니다. 

## 테스트를 기반으로 하는 AI를 통한 기능 개발과 없을 때의 기능개발은 차이가 있었나요?
AI가 테스트 코드의 결과도 확인하기 때문에 좀 더 안정적인 기능 구현을 하는 것 같긴 했습니다. 
하지만 이런 개발을 처음 해본 저는 AI를 컨트롤 하는 것부터가 큰 과제였기 때문에, 직접 개발하는 것보다 더 오래 걸리는 것 같기도 합니다. 잘 쓰기 위해서는 더 많은 실험이 필요합니다.

## AI의 응답을 개선하기 위해 추가했던 여러 정보(context)는 무엇인가요?
프로젝트의 아키텍처가 담긴 문서, 테스트 가이드라인. 

## 이 context를 잘 활용하게 하기 위해 했던 노력이 있나요?
CLAUDE.md에 경로를 명시합니다. 에이전트 프롬프트마다 한 번 더 얘기합니다.

## 생성된 여러 결과는 만족스러웠나요? AI의 응답을 어떤 기준을 갖고 '평가(evaluation)'했나요?
기능 명세와 같은 작업, 테스트 케이스나 테스트 코드의 초안 작성은 대체로 만족스럽습니다.
하지만 간단한 방법을 두고도 멀리 돌아갈 때가 있습니다. 
제가 명시한 지시를 잘 따르면 잘 응답했다고 생각했습니다. 

## AI에게 어떻게 질문하는것이 더 나은 결과를 얻을 수 있었나요? 시도했던 여러 경험을 알려주세요.
뭔가를 하지 말라고 하면 거기에 꽂힐 수 있기 때문에 관련한 것을 언급을 하지 않는 게 좋습니다.

## AI에게 지시하는 작업의 범위를 어떻게 잡았나요? 범위를 좁게, 넓게 해보고 결과를 적어주세요. 그리고 내가 생각하는 적절한 단위를 말해보세요.
처음에는 반복 기능을 통으로 던져봤습니다. 일단 오래 걸리고 너무 컨텍스트가 길어져서 고장이 나기 시작합니다. 그래서 다음엔 반복 기능 렌더링 하는 부분만 구현해보라고 했는데 기능 대비 절차가 너무 많아서 그건 그것대로 고장이 났습니다.
이번 과제 기준으로는 딱 '반복 일정 등록 시 캘린더에 반복 아이콘 표시'정도의 분량이 고장 안 나고 잘 만들어지는 분량이었습니다.

## 동기들에게 공유하고 싶은 좋은 참고자료나 문구가 있었나요? 마음껏 자랑해주세요.
https://kentcdodds.com/blog/static-vs-unit-vs-integration-vs-e2e-tests
통합테스트에 대한 글입니다.

## AI가 잘하는 것과 못하는 것에 대해 고민한 적이 있나요? 내가 생각하는 지점에 대해 작성해주세요.
차트나 캔버스 요소 같은 것을 시키면 인간은 눈으로 봤을 때 바로 이상하다고 생각하다는 걸 설명해주지 않으면 모릅니다.
미리 설정 해 놓은 것과 통일감 있게 개발하는 걸 잘 하는 것 같아요. 

## 마지막으로 느낀점에 대해 적어주세요!
이번 과제도 생각보다 오래 걸렸다..